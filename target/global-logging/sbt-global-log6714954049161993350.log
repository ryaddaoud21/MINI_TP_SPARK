[debug] > Exec(run, None, None)
[debug] Evaluating tasks: Compile / run
[debug] Running task... Cancel: Signal, check cycles: false, forcegc: true
[error] java.lang.RuntimeException: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Program Files\Hadoop\hadoop-2.7.1\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
[error] 	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:736)
[error] 	at org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:271)
[error] 	at org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:287)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
[error] 	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
[error] 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)
[error] 	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)
[error] 	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)
[error] 	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
[error] 	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)
[error] 	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)
[error] 	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)
[error] 	at com.crealytics.spark.excel.ExcelFileSaver.writeToWorkbook$1(ExcelFileSaver.scala:54)
[error] 	at com.crealytics.spark.excel.ExcelFileSaver.save(ExcelFileSaver.scala:61)
[error] 	at com.crealytics.spark.excel.DefaultSource.createRelation(DefaultSource.scala:72)
[error] 	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)
[error] 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
[error] 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
[error] 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
[error] 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
[error] 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[error] 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)
[error] 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)
[error] 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)
[error] 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)
[error] 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)
[error] 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
[error] 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
[error] 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
[error] 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
[error] 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
[error] 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)
[error] 	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)
[error] 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)
[error] 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)
[error] 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)
[error] 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)
[error] 	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)
[error] 	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)
[error] 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
[error] 	at AverageOrderValuePerCustomer$.main(AverageOrderValuePerCustomer.scala:50)
[error] 	at AverageOrderValuePerCustomer.main(AverageOrderValuePerCustomer.scala)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] 	at java.lang.reflect.Method.invoke(Method.java:498)
[error] 	at sbt.Run.invokeMain(Run.scala:144)
[error] 	at sbt.Run.execute$1(Run.scala:94)
[error] 	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:121)
[error] 	at sbt.Run$.executeSuccess(Run.scala:187)
[error] 	at sbt.Run.runWithLoader(Run.scala:121)
[error] 	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1988)
[error] 	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1927)
[error] 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[error] 	at scala.util.Try$.apply(Try.scala:213)
[error] 	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:367)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[error] 	at java.lang.Thread.run(Thread.java:750)
[error] Caused by: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Program Files\Hadoop\hadoop-2.7.1\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
[error] 	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:608)
[error] 	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:592)
[error] 	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:689)
[error] 	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
[error] 	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1691)
[error] 	at org.apache.hadoop.security.SecurityUtil.setConfigurationInternal(SecurityUtil.java:104)
[error] 	at org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:88)
[error] 	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:312)
[error] 	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:300)
[error] 	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:575)
[error] 	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2510)
[error] 	at scala.Option.getOrElse(Option.scala:201)
[error] 	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2510)
[error] 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:314)
[error] 	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2690)
[error] 	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:949)
[error] 	at scala.Option.getOrElse(Option.scala:201)
[error] 	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:943)
[error] 	at AverageOrderValuePerCustomer$.main(AverageOrderValuePerCustomer.scala:10)
[error] 	at AverageOrderValuePerCustomer.main(AverageOrderValuePerCustomer.scala)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] 	at java.lang.reflect.Method.invoke(Method.java:498)
[error] 	at sbt.Run.invokeMain(Run.scala:144)
[error] 	at sbt.Run.execute$1(Run.scala:94)
[error] 	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:121)
[error] 	at sbt.Run$.executeSuccess(Run.scala:187)
[error] 	at sbt.Run.runWithLoader(Run.scala:121)
[error] 	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1988)
[error] 	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1927)
[error] 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[error] 	at scala.util.Try$.apply(Try.scala:213)
[error] 	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:367)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[error] 	at java.lang.Thread.run(Thread.java:750)
[error] (Compile / run) java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Program Files\Hadoop\hadoop-2.7.1\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
[error] Total time: 37 s, completed 1 mars 2024 23:02:08
[debug] > Exec(idea-shell, None, None)
